package com.miniai.model.ngram;

import com.codeai.tokenizer.CodeTokenizer;
import com.google.gson.Gson;
import com.miniai.core.model.LanguageModel;
import com.miniai.core.tokenizer.Tokenizer;
import com.miniai.core.types.GenerateRequest;
import com.miniai.core.types.GenerateResponse;
import com.miniai.core.types.Usage;
import com.miniai.model.Sampler;
import com.miniai.model.smoothing.KneserNey;
import com.miniai.model.smoothing.SimpleBackoff;
import com.miniai.model.smoothing.SmoothingStrategy;
import com.miniai.tokenizer.WhitespaceTokenizer;

import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.util.*;

/**
 * N-gram ì–¸ì–´ ëª¨ë¸ (ì¼ë°˜í™”ëœ ë²„ì „)
 *
 * í•™ìŠµ í¬ì¸íŠ¸:
 * - Nì„ íŒŒë¼ë¯¸í„°ë¡œ ë°›ì•„ ì–´ë–¤ N-gramì´ë“  ì§€ì›
 * - Smoothing ì „ëµ êµì²´ ê°€ëŠ¥ (SimpleBackoff, KneserNey)
 * - ë¬¸ë§¥ ìœˆë„ìš°: N-1 í† í°
 *
 * ì˜ˆì‹œ (5-gram):
 * - ì…ë ¥: "for (int i = 0;"
 * - ë¬¸ë§¥: ë§ˆì§€ë§‰ 4í† í° ["i", "=", "0", ";"]
 * - ì˜ˆì¸¡: ë‹¤ìŒ í† í° í™•ë¥  ë¶„í¬
 */
public class NgramModel implements LanguageModel {

    private final NgramArtifact artifact;
    private final Tokenizer tokenizer;
    private final SmoothingStrategy smoothing;
    private final Map<Integer, String> reverseVocab;

    /**
     * ê¸°ë³¸ ìƒì„±ì (SimpleBackoff ì‚¬ìš©)
     */
    public NgramModel(NgramArtifact artifact, Tokenizer tokenizer) {
        this(artifact, tokenizer, new SimpleBackoff());
    }

    /**
     * Smoothing ì „ëµ ì§€ì • ìƒì„±ì
     */
    public NgramModel(NgramArtifact artifact, Tokenizer tokenizer, SmoothingStrategy smoothing) {
        this.artifact = artifact;
        this.tokenizer = tokenizer;
        this.smoothing = smoothing;

        // Reverse vocabulary ìƒì„± (id â†’ word)
        this.reverseVocab = new HashMap<>();
        for (Map.Entry<String, Integer> entry : artifact.getVocabulary().entrySet()) {
            reverseVocab.put(entry.getValue(), entry.getKey());
        }
    }

    @Override
    public GenerateResponse generate(GenerateRequest request) {
        long startTime = System.currentTimeMillis();

        // 1. í”„ë¡¬í”„íŠ¸ í† í°í™”
        List<Integer> tokens = new ArrayList<>(tokenizer.encode(request.getPrompt()));
        int inputTokenCount = tokens.size();

        // 2. Sampler ìƒì„±
        Long seed = request.getSeed().orElse(System.currentTimeMillis());
        Sampler sampler = new Sampler(request.getTemperature(), request.getTopK(), seed);
        int n = artifact.getN();

        for (int i = 0; i < request.getMaxTokens(); i++) {
            // ë¬¸ë§¥ ì¶”ì¶œ (ë§ˆì§€ë§‰ N-1ê°œ í† í°)
            int contextStart = Math.max(0, tokens.size() - (n - 1));
            List<Integer> context = tokens.subList(contextStart, tokens.size());

            // ë‹¤ìŒ í† í° í™•ë¥  ë¶„í¬ (smoothing ì ìš©)
            Map<Integer, Double> probs = smoothing.getSmoothedProbabilities(artifact, context);

            if (probs.isEmpty()) {
                break; // ë” ì´ìƒ ìƒì„± ë¶ˆê°€
            }

            // í™•ë¥ ì„ ì¹´ìš´íŠ¸ë¡œ ë³€í™˜ (Samplerê°€ Integer ì¹´ìš´íŠ¸ë¥¼ ë°›ìŒ)
            Map<Integer, Integer> counts = probsToCounts(probs);

            // ìƒ˜í”Œë§
            int nextToken = sampler.sample(counts);

            // Stop sequence ì²´í¬
            String nextWord = reverseVocab.getOrDefault(nextToken, "[UNK]");
            if (request.getStopSequences() != null && request.getStopSequences().contains(nextWord)) {
                break;
            }

            tokens.add(nextToken);
        }

        // 3. ê²°ê³¼ ë””ì½”ë”©
        String generatedText = tokenizer.decode(tokens);

        // 4. Usage ê³„ì‚°
        int outputTokenCount = tokens.size() - inputTokenCount;
        Usage usage = new Usage(inputTokenCount, outputTokenCount);

        long latency = System.currentTimeMillis() - startTime;

        return new GenerateResponse(generatedText, usage, latency, modelName());
    }

    /**
     * í™•ë¥  ë¶„í¬ë¥¼ ì¹´ìš´íŠ¸ë¡œ ë³€í™˜ (Sampler í˜¸í™˜ìš©)
     * í™•ë¥ ì„ 1000ë°°ë¡œ ìŠ¤ì¼€ì¼ì—…í•˜ì—¬ ì •ìˆ˜ë¡œ ë³€í™˜
     */
    private Map<Integer, Integer> probsToCounts(Map<Integer, Double> probs) {
        Map<Integer, Integer> counts = new HashMap<>();
        for (Map.Entry<Integer, Double> entry : probs.entrySet()) {
            // í™•ë¥ ì„ 1000ë°°í•˜ì—¬ ì •ìˆ˜ ì¹´ìš´íŠ¸ë¡œ ë³€í™˜
            int count = (int) (entry.getValue() * 1000) + 1; // ìµœì†Œ 1
            counts.put(entry.getKey(), count);
        }
        return counts;
    }

    @Override
    public String modelName() {
        return artifact.getN() + "-gram-v1";
    }

    public NgramArtifact getArtifact() {
        return artifact;
    }

    public SmoothingStrategy getSmoothing() {
        return smoothing;
    }

    /**
     * Artifact íŒŒì¼ë¡œë¶€í„° ëª¨ë¸ ë¡œë“œ
     */
    public static NgramModel fromArtifact(Path artifactPath) throws IOException {
        return fromArtifact(artifactPath, new SimpleBackoff());
    }

    /**
     * Artifact íŒŒì¼ë¡œë¶€í„° ëª¨ë¸ ë¡œë“œ (Smoothing ì „ëµ ì§€ì •)
     */
    public static NgramModel fromArtifact(Path artifactPath, SmoothingStrategy smoothing) throws IOException {
        String json = Files.readString(artifactPath);
        Gson gson = new Gson();
        NgramArtifact artifact = gson.fromJson(json, NgramArtifact.class);

        // í† í¬ë‚˜ì´ì € íƒ€ì…ì— ë”°ë¼ ìƒì„±
        String tokenizerType = artifact.getMetadata().getTokenizerType();
        Tokenizer tokenizer;

        if ("CodeTokenizer".equals(tokenizerType)) {
            tokenizer = new CodeTokenizer(artifact.getVocabulary());
            System.out.println("ğŸ”§ " + artifact.getN() + "-gram ëª¨ë¸ ë¡œë“œ: CodeTokenizer ì‚¬ìš©");
        } else {
            tokenizer = new WhitespaceTokenizer(artifact.getVocabulary());
            System.out.println("ğŸ“ " + artifact.getN() + "-gram ëª¨ë¸ ë¡œë“œ: WhitespaceTokenizer ì‚¬ìš©");
        }

        System.out.println("ğŸ“Š Smoothing: " + smoothing.description());

        return new NgramModel(artifact, tokenizer, smoothing);
    }

    /**
     * Kneser-Ney Smoothingìœ¼ë¡œ ëª¨ë¸ ë¡œë“œ
     */
    public static NgramModel fromArtifactWithKneserNey(Path artifactPath) throws IOException {
        return fromArtifact(artifactPath, new KneserNey());
    }

    @Override
    public String toString() {
        return String.format("NgramModel(n=%d, vocab=%d, smoothing=%s)",
            artifact.getN(),
            artifact.getVocabulary().size(),
            smoothing.strategyName());
    }
}
